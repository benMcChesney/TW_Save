{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalize notebook and load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependencies loaded.\n",
      "loading esf paths from file @  turn_one.txt\n",
      "notebook initialized\n"
     ]
    }
   ],
   "source": [
    "import esf_utils\n",
    "import os \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import configparser\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "print ( 'dependencies loaded.')\n",
    "\n",
    "campaign_esf_paths_file = 'turn_one.txt'\n",
    "campaign_files = esf_utils.parse_campaign_files_txt( campaign_esf_paths_file )\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "esf2xml_dir =  config['dependencies']['esf2xml']\n",
    "save_folder = config['paths']['save_game_folder']\n",
    "output_folder = config['paths']['output_folder']\n",
    "extracted_subfolder = config['paths']['extracted_subfolder']\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print('notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for parsing a file \n",
    "econ_array = []\n",
    "army_array = [] \n",
    "region_array = []\n",
    "\n",
    "max = len(campaign_files)-1\n",
    "i = 0 \n",
    "\n",
    "#for s in campaign_files:\n",
    "s = \"Clan Skryre_turn1.11510108040.save\"\n",
    "save_file_clean = esf_utils.clean_filename( s )\n",
    "out = output_folder\n",
    "templated = out.replace( '[$filename]', save_file_clean )\n",
    "\n",
    "full_path = os.path.join( save_folder , s )\n",
    "#output_dir =  f\"{save_file_clean}_extract\"\n",
    "file_modstamp = os.path.getmtime(full_path)\n",
    "ts = datetime.datetime.fromtimestamp( file_modstamp )\n",
    "unix_timestamp = int(time.mktime(ts.timetuple()))\n",
    "\n",
    "try:\n",
    "    dat1 = esf_utils.extract_save_file( \n",
    "    save_folder \n",
    "    , s\n",
    "    ,templated\n",
    "    ,config \n",
    "    )\n",
    "except:\n",
    "    print(\"An exception occurred while extracting\")\n",
    "\n",
    "\n",
    "extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "try :\n",
    "    session_id = esf_utils.get_session_guid( extracted_output )[1]\n",
    "    turn_num = esf_utils.get_turn_number( extracted_output )\n",
    "\n",
    "    # for faction economics at a high KPI level\n",
    "    new_array = []\n",
    "    esf_utils.parse_extracted_factions_folder( extracted_output, new_array ) \n",
    "    for r in new_array:\n",
    "        r[\"session_id\"] = session_id\n",
    "        r[\"turn_num\"] = turn_num\n",
    "        r[\"modifiedOn\"] = unix_timestamp\n",
    "        econ_array.append( r ) \n",
    "    econ_df = pd.DataFrame( econ_array )\n",
    "    econ_df.to_csv('export_faction_economy.csv')\n",
    "    \n",
    "    # parse army information\n",
    "    new_array = []\n",
    "    #session_id, session_guid, turn_num = \n",
    "    esf_utils.parse_extracted_armies_folder( extracted_output, new_array ) \n",
    "\n",
    "    # write in all data universal to this save file\n",
    "    for r in new_array:\n",
    "        r[\"session_id\"] = session_id\n",
    "        r[\"turn_num\"] = turn_num\n",
    "        r[\"modifiedOn\"] = unix_timestamp\n",
    "        army_array.append( r )\n",
    "    army_df = pd.DataFrame( army_array )\n",
    "    army_df.to_csv('export_army_unit.csv')\n",
    "\n",
    "    # parse region information\n",
    "    new_array = []\n",
    "    esf_utils.parse_extracted_region_folder( extracted_output, new_array ) \n",
    "    \n",
    "        # write in all data universal to this save file\n",
    "    for r in new_array:\n",
    "        r[\"session_id\"] = session_id\n",
    "        r[\"turn_num\"] = turn_num\n",
    "        r[\"modifiedOn\"] = unix_timestamp\n",
    "        region_array.append( r )\n",
    "    region_df = pd.DataFrame( region_array ) \n",
    "    region_df.to_csv( 'export_region.csv' )\n",
    "    \n",
    "    # first run - get province hierarchy \n",
    "    if i == 0 :\n",
    "        print ( 'parsing province xml data')\n",
    "        new_array = []\n",
    "        esf_utils.parse_province_campaign_data( extracted_output , new_array )\n",
    "        province_df = pd.DataFrame( new_array )\n",
    "        province_df.to_csv( 'export_province.csv')\n",
    "except:\n",
    "    print(\"An exception occurred while extracting\")\n",
    "\n",
    "#print( f\"@ { i }  / { max } folders loaded and exported\")\n",
    "#i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just testing extract_regions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in campaign_files:\n",
    "    save_file_clean = esf_utils.clean_filename( s )\n",
    "    out = output_folder\n",
    "    templated = out.replace( '[$filename]', save_file_clean )\n",
    "    full_path = os.path.join( save_folder , s )   \n",
    "    extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "    # for region and control \n",
    "    new_array = []\n",
    "    esf_utils.parse_extracted_region_folder( extracted_output, new_array ) \n",
    "    region_df = pd.DataFrame( new_array )\n",
    "    region_df.to_csv( 'export_region.csv' , index=False )\n",
    "    print ( 'exported to region.csv')   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just provinces \n",
    "\n",
    "\n",
    "def parse_province_campaign_data( extracted_output, new_array ):\n",
    "    full_path = os.path.join( extracted_output , 'campaign_env' , 'world-0000.xml' ) \n",
    "    xml = ET.parse( full_path ).getroot()    \n",
    "\n",
    "    # get name NK of region from file, NOT filename \n",
    "    province_xml = xml.findall( \"./rec/ary/rec[@type = 'PROVINCE_ARRAY']\")\n",
    "\n",
    "    xml_index = 0 \n",
    "    for province in province_xml: \n",
    "\n",
    "        #if xml_index == 0 :\n",
    "        # parse for testing \n",
    "        province_name = province.findall( './asc')[0].text \n",
    "        #print ( 'province name is ' , province_name ) \n",
    "\n",
    "        region_blocks = province.findall( \"./rec/rec/ary/rec/asc\" )\n",
    "        #print ( 'length of region blocks ', len( region_blocks ) )\n",
    "        for region in region_blocks : \n",
    "            data_row = {\n",
    "                'province_name' : province_name\n",
    "                ,'settlement_key' : region.text\n",
    "            }\n",
    "            new_array.append( data_row )\n",
    "    xml_index = xml_index + 1\n",
    "\n",
    "for s in campaign_files:\n",
    "    save_file_clean = esf_utils.clean_filename( s )\n",
    "    out = output_folder\n",
    "    templated = out.replace( '[$filename]', save_file_clean )\n",
    "    full_path = os.path.join( save_folder , s )   \n",
    "    extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "    # for characters\n",
    "    new_array = []\n",
    "    esf_utils.parse_extracted_region_folder( extracted_output, new_array ) \n",
    "    region_df = pd.DataFrame( new_array )\n",
    "    region_df.to_csv( 'export_region.csv' , index=False )\n",
    "    print ( 'exported to region.csv')   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just character \n",
    "\n",
    "\n",
    "def parse_character_campaign_data( extracted_output, new_array ):\n",
    "\n",
    "    print( 'getting character data from ', extracted_output )\n",
    "\n",
    "    #print ( 'debugger')\n",
    "    # get factions data\n",
    "    character_dir = os.path.join( extracted_output , \"character\" )\n",
    "\n",
    "\n",
    "    arr = os.listdir( character_dir )\n",
    "    for file in os.listdir( character_dir ):\n",
    "        #print('file', file )\n",
    "        if file.endswith(\".xml\"):\n",
    "            if file.find(\"general\") != -1:\n",
    "                # parse_faction_xml( factions_dir , file, data_array )\n",
    "                \n",
    "                full_path = os.path.join( character_dir , file ) \n",
    "                print(full_path )\n",
    "                xml = ET.parse( full_path ).getroot()\n",
    "                \n",
    "                coord_xpath = \"./rec/rec[@type = 'LOCOMOTABLE']/v2\"   \n",
    "                coords = xml.findall( coord_xpath )[0]\n",
    "\n",
    "                x = coords.attrib['x']\n",
    "                y = coords.attrib['y']\n",
    "                print( coords , x ,y ) \n",
    "                \n",
    "                details_xpath = \"./rec/rec[@type = 'CHARACTER_DETAILS']/asc\"   \n",
    "                detail_tags = xml.findall( details_xpath )\n",
    "                faction = detail_tags[0].text \n",
    "                type = detail_tags[2].text \n",
    "                key = detail_tags[3].text\n",
    "\n",
    "                data_row = {\n",
    "                    'faction' : faction\n",
    "                    ,'type' : type\n",
    "                    ,'key' : key \n",
    "                    , 'loc.x' : x\n",
    "                    , 'loc.y' : y  \n",
    "                }\n",
    "                new_array.append( data_row )\n",
    "                print('debugger')\n",
    "\n",
    "                '''\n",
    "                campaign_tags = mf_xml.findall( \"./rec/rec/[@type = 'LOCOMOTABLE']\" )[0] \n",
    "                localized = campaign_tags.findall( \"asc\")\n",
    "                unit_campaign_name = localized[0].text\n",
    "\n",
    "                if ( unit_campaign_name is None ):\n",
    "                    unit_campaign_name = 'null'\n",
    "\n",
    "                '''\n",
    "\n",
    "for s in campaign_files:\n",
    "    save_file_clean = esf_utils.clean_filename( s )\n",
    "    out = output_folder\n",
    "    templated = out.replace( '[$filename]', save_file_clean )\n",
    "    full_path = os.path.join( save_folder , s )   \n",
    "    extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "    # for characters\n",
    "    new_array = []\n",
    "    parse_character_campaign_data( extracted_output , new_array )\n",
    "\n",
    "    \n",
    "    #esf_utils.parse_extracted_region_folder( extracted_output, new_array ) \n",
    "    characters_df = pd.DataFrame( new_array )\n",
    "    region_df.to_csv( 'export_region.csv' , index=False )\n",
    "    print ( 'exported to region.csv')   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "xml_path = \"./extract/Clan_Skryre_Auto_save.171597358761.save_extract/extract/army/ARMY-0001.xml\"\n",
    "\n",
    "xml  = ET.parse( xml_path ).getroot()\n",
    "\n",
    "mf_legacy = \"./rec/rec/rec/[@type = 'MILITARY_FORCE_LEGACY_HISTORY']\"\n",
    "mf_legacy_xml = xml.find( mf_legacy )\n",
    "char_path = \"./rec/ary/rec/rec/asc\"\n",
    "name_tags = mf_legacy_xml.findall( char_path )\n",
    "tags_list = []\n",
    "for tag in name_tags : \n",
    "    if tag.text != None :\n",
    "        tags_list.append( tag.text ) \n",
    "name_nk = '_'.join(tags_list)\n",
    "\n",
    "#mf_xpath = \"./rec/[@type = 'MILITARY_FORCE']\"   \n",
    "#mf_xml = xml.findall( mf_xpath )[0]\n",
    "#name_blocks = \"./rec/rec[@type = 'CHARACTER_DETAILS']/\"  \n",
    "'''\n",
    "  units_arr_xpath = \"./rec/ary/rec/rec/[@type = 'UNIT']\"\n",
    "    units_xml = mf_xml.findall( units_arr_xpath )\n",
    "\n",
    "    faction_name_xpath = \"./rec/[@type='COMMANDER_DETAILS']/asc\"\n",
    "'''\n",
    "\n",
    "\n",
    "print( 'debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "# turn 3 \n",
    "xml_path = \"./extract/ikit_claw_turn1_battle_ar.13389809406.save_extract/extract/campaign_env/campaign_model-0000.xml\"\n",
    "#\"./extract/Clan_Skryre_Auto_save.31597358761.save_extract/extract/campaign_env/campaign_model-0000.xml\"\n",
    "_parser = etree.XMLParser(recover=True)\n",
    "xml = ET.parse( xml_path , parser = _parser )\n",
    "br_xpath = \"./rec/rec/[@type = 'BATTLE_RESULTS']/\"\n",
    "br_tags = xml.findall( br_xpath )\n",
    "\n",
    "\n",
    "ally_xpath =  \"./rec/rec/rec/ary/[@type='ALLIANCES']\"\n",
    "ally_tags = xml.findall( ally_xpath )\n",
    "\n",
    "xpath =       \"./rec/rec/rec/ary/[@type='ALLIANCES']/rec/rec/ary/rec/rec/rec\"\n",
    "\n",
    "bsf_tags = xml.findall( xpath )\n",
    "\n",
    "ally_xpath =  \"./rec/rec/rec/ary/[@type='ALLIANCES']\"\n",
    "ally_tags = xml.findall( ally_xpath )\n",
    "#battle_result_xpath = \"./rec/rec/rec/ary/[@type='ALLIANCES']/rec\"\n",
    "battle_result_xpath = \"./rec/rec/rec/ary/rec/[@type='BATTLE_RESULT_ALLIANCE']/\"\n",
    "brx = xml.findall( battle_result_xpath  )\n",
    "# direct past \n",
    "bra = \"./rec/rec/rec/ary/rec/[@type ='BATTLE_RESULT_ALLIANCE']/\"\n",
    "bra_tags = xml.findall( battle_result_xpath )\n",
    "'''\n",
    "<rec type=\"BATTLE_RESULTS\" version=\"2\">\n",
    "   <yes/>\n",
    "   <i>0</i>\n",
    "   <u>615</u>\n",
    "   <flt>-1.0</flt>\n",
    "   <ary type=\"ALLIANCES\">\n",
    "    <rec type=\"ALLIANCES\">\n",
    "     <rec type=\"BATTLE_RESULT_ALLIANCE\" version=\"7\">\n",
    "'''\n",
    "#for t in bsf_tags : \n",
    "asc_tags = xml.findall( f\"{xpath}/asc\")\n",
    "faction = asc_tags[0].text  \n",
    "\n",
    "flt_tags = xml.findall( f\"{xpath}/flt\")\n",
    "\n",
    "json = {} \n",
    "for i in range ( 0 , 21 ):\n",
    "  json[ f\"bsa_float_{i}\"] = flt_tags[i].text\n",
    "\n",
    "print( 'debugger')\n",
    "\n",
    "for t in br_tags : \n",
    "  ''' <yes/>\n",
    "   <i>0</i>\n",
    "   <u>366</u>\n",
    "   <flt>-1.0</flt>'''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "# turn 3 \n",
    "xml_path = \"./extract/ikit_claw_turn1_battle_ar.13389809406.save_extract/extract/campaign_env/campaign_model-0000.xml\"\n",
    "_parser = etree.XMLParser(recover=True)\n",
    "xml = ET.parse( xml_path , parser = _parser )\n",
    "br_xpath = \"./rec/rec/[@type = 'BATTLE_RESULTS']\"\n",
    "br_tags = xml.findall( br_xpath )\n",
    "\n",
    "xpath = f\"{br_xpath}/ary/[ @type = 'ALLIANCES']/rec/\"\n",
    "xtags = xml.findall( xpath )\n",
    "\n",
    "# setup battle stats\n",
    "json = {}\n",
    "for tag in xtags:\n",
    "   battle_data = tag.findall( 'u' )\n",
    "   if len( battle_data ) >= 6 : \n",
    "      json[ 'deployed' ] = battle_data[0].text\n",
    "      json[ 'remaining' ] = battle_data[2].text\n",
    "      json[ 'lost' ] = battle_data[4].text\n",
    "      json[ 'killed' ] = battle_data[6].text\n",
    "\n",
    "# f\"{br_xpath}/ary/[ @type = 'ALLIANCES']/rec/rec/ary/rec/rec/rec\" #[ @type = 'BATTLE_RESULT_UNIT' ]/\"\n",
    "\n",
    "# fun fact - ending in / gets all children, not / gets all tags \n",
    "army_units_xpath1 = f\"{br_xpath}/ary/[ @type = 'ALLIANCES']/rec/rec/ary/rec/rec/ary[ @type = 'UNITS']/rec[ @type = 'UNITS']/rec[ @type = 'BATTLE_RESULT_UNIT']\"\n",
    "army_units_xpath2 = f\"{army_units_xpath1}\"\n",
    "army_units_tags = xml.findall( army_units_xpath2 )\n",
    "\n",
    "unit_result_array = [] \n",
    "for t in army_units_tags : \n",
    "   unit_data = t.findall( 'u') \n",
    "\n",
    "   json = {} \n",
    "   if len( unit_data ) >= 6 :\n",
    "      json[ 'kills'] = unit_data[4].text\n",
    "      json[ 'start_num_units'] = unit_data[0].text\n",
    "      json[ 'end_num_units'] = unit_data[1].text\n",
    "      unit_result_array.append ( json ) \n",
    "\n",
    "   unit_string_data = t.findall( 's') \n",
    "   if len( unit_data ) >= 1 :\n",
    "      json[ 'unit_name'] = unit_string_data[0].text \n",
    "\n",
    "   unit_result_array.append( json )\n",
    "\n",
    "   print( 'debugger')\n",
    "\n",
    "# u[5] = kills\n",
    "# u[0] = start num units\n",
    "# u[1] = end num units\n",
    "\n",
    "print( 'debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import copy \n",
    "# turn 3 \n",
    "xml_path = \"./extract/ikit_claw_turn1_battle_ar.13389809406.save_extract/extract/campaign_env/campaign_model-0000.xml\"\n",
    "_parser = etree.XMLParser(recover=True)\n",
    "xml = ET.parse( path , parser = _parser )\n",
    "\n",
    "br_xpath = \"./rec/rec/[@type = 'BATTLE_RESULTS']\"\n",
    "# fun fact - ending in / gets all children, not / gets all tags \n",
    "#army_units_xpath1 = f\"{br_xpath}/ary/[ @type = 'ALLIANCES']/rec/rec/ary/rec/rec/ary[ @type = 'UNITS']/rec[ @type = 'UNITS']/rec[ @type = 'BATTLE_RESULT_UNIT']\n",
    "br_army_xpath = f\"{br_xpath}/ary/[ @type = 'ALLIANCES']/rec/rec/ary/rec/rec[ @type = 'BATTLE_RESULT_ARMY']\"\n",
    "br_army_tags = xml.findall( br_army_xpath )\n",
    "\n",
    "#new_array = [] \n",
    "# Iterate within each army - link these together somehow \n",
    "for army in br_army_tags:\n",
    "\n",
    "    army_json = {} \n",
    "    # BATTLE_SETUP_FACTION\n",
    "    faction_xpath = f\"./rec[ @type='BATTLE_SETUP_FACTION']/asc\"\n",
    "    faction_tags = army.findall( faction_xpath )\n",
    "    faction_nk = faction_tags[0].text\n",
    "    \n",
    "    army_attrib_xpath =  f\"./s\"\n",
    "    army_attrib_tags = army.findall( army_attrib_xpath )\n",
    "\n",
    "    ui_path_xpath = f\"./asc\"\n",
    "    ui_path_tags = army.findall( ui_path_xpath )\n",
    "\n",
    "    army_json[ 'leader'] = army_attrib_tags[0].text \n",
    "    army_json[ 'ui_path'] =  ui_path_tags[0].text\n",
    "    army_json[ 'faction_nk'] = faction_nk\n",
    "\n",
    "    # now parse individual units\n",
    "    bru_xpath = \"./ary[ @type = 'UNITS']/rec[ @type = 'UNITS']/rec[ @type = 'BATTLE_RESULT_UNIT']\"\n",
    "    bru_tags = army.findall( bru_xpath )\n",
    "\n",
    "    for t in bru_tags : \n",
    "        unit_data = t.findall( 'u') \n",
    "\n",
    "        json = copy.deepcopy(army_json) \n",
    "        if len( unit_data ) >= 6 :\n",
    "            json[ 'kills'] = unit_data[4].text\n",
    "            json[ 'start_num_units'] = unit_data[0].text\n",
    "            json[ 'end_num_units'] = unit_data[1].text\n",
    "\n",
    "        unit_string_data = t.findall( 's') \n",
    "        if len( unit_data ) >= 1 :\n",
    "            json[ 'unit_name'] = unit_string_data[0].text \n",
    "\n",
    "        new_array.append ( json ) \n",
    "\n",
    "        print( 'debuger')\n",
    "\n",
    "    print( 'debuger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## added 2021/12/15\n",
    "## Diplomacy per faction \n",
    "def parse_diplomacy_from_factions_folder( extracted_output, data_array ):\n",
    "\n",
    "\n",
    "    factions_dir = os.path.join( extracted_output , \"factions\" )\n",
    "    arr = os.listdir( factions_dir )\n",
    "    for file in os.listdir( factions_dir ):\n",
    "        if file.endswith(\".xml\"):\n",
    "            full_path = os.path.join( factions_dir , file )\n",
    "            full_path = \"C:/lab/tw_save/extract/Clan_Skryre_attack_2.1327371162.save_extract/extract/factions/wh2_main_skv_clan_skyre.xml\"\n",
    "            tree = ET.parse( full_path )\n",
    "            root = tree.getroot()\n",
    "            row = {} \n",
    "            #xpath = f\"./rec/rec/ary/rec/[@type='OLD_DIPLOMACY_RELATIONSHIP']\"rec[ @type = 'BATTLE_RESULT_ARMY']\n",
    "            xpath = f\"./rec/[ @type = 'OLD_DIPLOMACY_MANAGER']/ary/rec[ @type='DIPLOMACY_RELATIONSHIPS_ARRAY']\"        \n",
    "            tags = root.findall( xpath )\n",
    "\n",
    "            for tag in tags :\n",
    "\n",
    "                u_tags = tag.findall( f\"./rec/u\" )    \n",
    "                for x in range ( 0 , len( u_tags )):\n",
    "                    row[ f\"u_{x}\"] = u_tags[x].text \n",
    "\n",
    "                i_tags = tag.findall( f\"./rec/i\" )    \n",
    "                for x in range ( 0 , len( i_tags )):\n",
    "                    row[ f\"i_{x}\"] = i_tags[x].text \n",
    "\n",
    "                asc_tags = tag.findall( f\"./rec/asc\" )    \n",
    "                for x in range ( 0 , len( asc_tags )):\n",
    "                    row[ f\"asc_{x}\"] = asc_tags[x].text \n",
    "                    \n",
    "                #tags = root.findall( xpath ) \n",
    "                faction_data = esf_utils.parse_faction_metadata( root )\n",
    "                row['faction_name'] = faction_data['faction_name']\n",
    "                row['faction_id'] = faction_data['faction_id']\n",
    "                data_array.append( row )\n",
    "\n",
    "\n",
    "for s in campaign_files:\n",
    "    save_file_clean = esf_utils.clean_filename( s )\n",
    "    out = output_folder\n",
    "    templated = out.replace( '[$filename]', save_file_clean )\n",
    "    full_path = os.path.join( save_folder , s )   \n",
    "    extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "    # for characters\n",
    "    new_array = []\n",
    "    parse_diplomacy_from_factions_folder( extracted_output, new_array ) \n",
    "    region_df = pd.DataFrame( new_array )\n",
    "    region_df.to_csv( 'export_diplomacy.csv' , index=False )\n",
    "    print ( 'exported to region.csv')   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching to SQL to use less memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE tw_economy\n",
      "DROP TABLE tw_regions\n",
      "skipping extract...\n",
      "getting economy data from  extract\\Clan_Skryre_turn1.11510108040.save_extract\\extract\\\n",
      "['bank_balance', 'taxes', 'army_upkeep', 'faction_name', 'faction_id', 'session_guid_id', 'turn_num', 'modifiedOn']\n",
      "exporting 348 rows to tw_economy \n",
      "348 rows written to table tw_economy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import esf_utils\n",
    "import os \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import configparser\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "def create_data_output( label , destination ) :\n",
    "    \n",
    "    obj = { \n",
    "        \"array\" : []\n",
    "        , \"destination\" : destination\n",
    "    }\n",
    "    return obj \n",
    "\n",
    "def apply_metadata( df, session_id, turn_num , modifiedOn ):\n",
    "    df[ 'session_guid_id' ] = session_id \n",
    "    df[ 'turn_num' ] = turn_num \n",
    "    df[ 'modifiedOn' ] = modifiedOn\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return df \n",
    "\n",
    "econ = create_data_output( \"economy\" , \"tw_economy\")\n",
    "army = create_data_output( \"army\" , \"tw_army_units\")\n",
    "region = create_data_output( \"region\" , \"tw_regions\")\n",
    "outputs = [ econ, army, region ]\n",
    "\n",
    "user = \"dbt_sqlserver\"\n",
    "pwd = \"dbt_sqlserver\"\n",
    "server = '(local)' \n",
    "database = 'tw_save' \n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "#\"mssql+pyodbc://user:pwd@server/database\"\n",
    "conn_string = f\"mssql+pyodbc://{user}:{pwd}@{server}/{database}?driver={driver}&trusted_connection=Yes\"\n",
    "engine = sqlalchemy.create_engine( conn_string , echo=False) \n",
    "engine.connect() ; \n",
    "\n",
    "sql_scripts = \"\"\"\n",
    "SELECT\n",
    "  TABLE_NAME\n",
    "FROM\n",
    "  tw_save.INFORMATION_SCHEMA.TABLES\n",
    "where table_name like 'tw_%'\n",
    "\"\"\"\n",
    "conn = engine.raw_connection()\n",
    "\n",
    "tables_df = pd.read_sql( sql_scripts , conn )\n",
    "tables = list(tables_df[\"TABLE_NAME\"])\n",
    "for o in outputs : \n",
    "    dest = o[\"destination\"]\n",
    "    if dest in tables :\n",
    "        cmd = f'DROP TABLE {dest}' \n",
    "        conn.execute( cmd )\n",
    "        print ( cmd )\n",
    "\n",
    "s = \"Clan Skryre_turn1.11510108040.save\"\n",
    "save_file_clean = esf_utils.clean_filename( s )\n",
    "out = output_folder\n",
    "templated = out.replace( '[$filename]', save_file_clean )\n",
    "full_path = os.path.join( save_folder , s )\n",
    "file_modstamp = os.path.getmtime(full_path)\n",
    "ts = datetime.datetime.fromtimestamp( file_modstamp )\n",
    "unix_timestamp = int(time.mktime(ts.timetuple()))\n",
    "\n",
    "try:\n",
    "    dat1 = esf_utils.extract_save_file( \n",
    "    save_folder \n",
    "    , s\n",
    "    ,templated\n",
    "    ,config \n",
    "    )\n",
    "except:\n",
    "    print(\"An exception occurred while extracting\")\n",
    "\n",
    "\n",
    "extracted_output = os.path.join(templated, extracted_subfolder)\n",
    "\n",
    "#try :\n",
    "session_id = esf_utils.get_session_guid( extracted_output )[1]\n",
    "turn_num = esf_utils.get_turn_number( extracted_output )\n",
    "\n",
    "# for faction economics at a high KPI level\n",
    "new_array = []\n",
    "esf_utils.parse_extracted_factions_folder( extracted_output, new_array ) \n",
    "econ_df = pd.DataFrame( new_array )\n",
    "econ_df = apply_metadata( econ_df , session_id , turn_num, unix_timestamp ) \n",
    "\n",
    "#econ_df.columns = econ_df.columns.astype(str)\n",
    "#print( list( econ_df.columns ) )\n",
    "dest = econ[\"destination\"]\n",
    "#print(f\"exporting { len( econ_df ) } rows to { dest } \" )\n",
    "\n",
    "conn = engine.connect()\n",
    "#econ_df = econ_df.fillna( \"NULL\" )\n",
    "\n",
    "top_df = econ_df.head(0) \n",
    "top_df.to_sql(  name=dest , con=conn, if_exists=\"replace\", index=False ) \n",
    "#conn.execute( f\"TRUNCATE TABLE {dest}\" )\n",
    "econ_df.to_sql( name=dest , con=conn, index=False, if_exists=\"append\" )\n",
    "\n",
    "print( f\"{len( econ_df )} rows written to table { econ['destination']}\" )\n",
    "\n",
    "#except:\n",
    "#    print(\"An exception occurred while extracting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68bf38532125f830937b5b0fa21162aa884577d1b02842ef719f4091a6bcfc6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tw_save': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
